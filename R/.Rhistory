library(knitr)
#rstudio will set the folder where .Rmd file seats as work directory
#set it back to the folder where .Rproj seats
opts_knit$set(root.dir = normalizePath("../"))
opts_chunk$set(fig.align = 'center', cache = FALSE, warning = FALSE,
message = TRUE, echo = FALSE)
options(digits = 3, width = 88, knitr.graphics.auto_pdf = TRUE,
knitr.kable.NA = '')
# download template files if not available
tpl_1 = 'https://raw.githubusercontent.com/daijiang/workflow_demo/master/template/preamble.tex'
tpl_2 = 'https://raw.githubusercontent.com/daijiang/workflow_demo/master/template/doc_prefix.tex'
# bib_1 = 'https://raw.githubusercontent.com/daijiang/workflow_demo/master/template/ref.bib'
# change directory accordingly
if(!file.exists(tpl_1f <- '../template/preamble.tex')) download.file(tpl_1, tpl_1f)
if(!file.exists(tpl_2f <- '../template/doc_prefix.tex')) download.file(tpl_2, tpl_2f)
if(knitr::is_latex_output() | knitr::is_html_output()){
library(kableExtra)
} else {
options(kableExtra.auto_format = FALSE) # for docx
}
#library(rmarkdown)    # You need this library to run this template.
#library(epuRate)
library(magrittr)
library(tidyverse)
library(cowplot)
library(readr)
library(wesanderson)
#library(rjson)
library(RJSONIO)
library(cowplot)
library(rlang)
library(kableExtra)
library(scales)
#library(lme4) # for mixed effects modelling
source("../R/R_rainclouds.R") # for the raincloud plot
#source("R/R_rainclouds.R")
paradigm.fig.pth <- '../images/Fig_ROIs.png'
#paradigm.fig <- readPNG(paradigm.fig.pth, native=TRUE, info=TRUE)
include_graphics(paradigm.fig.pth)
paradigm.fig.pth <- '../images/Fig_Paradigm.png'
#paradigm.fig <- readPNG(paradigm.fig.pth, native=TRUE, info=TRUE)
include_graphics(paradigm.fig.pth)
# Show it:
TRs <- data.frame(TR=c(700, 1510, 1920),
TE=c('10, 30.56','19.4','22'),
VoxSizeIso = c(2, 1.5, 1.5),
PhaseEncodingDirGRAPPA = c('2','3','2'),
MultiBandFactor=c('4','3','CAiPI shift 1'),
ExcitFlipAngle=c(35,60,15),
ReceiverBand_Hz_Px=c(1930,1116,1116),
partFourier=c('5/8','6/8','6/8'),
FOV=c('192 x 192 x 96','192 x 192 x 122','192 x 192 x 120'),
Nslices=c(48,81,80))
rownames(TRs) <- c("P1", "P2", "P3")
kable(t(TRs), caption="Table 1. Compared Protocols")
#%>% kable_classic(full_width=F, html_font="Cambria")
# source the data wrangling functions
source('../R/data_wrangles.R')
subjects = c(1, 2, 3, 4, 5)
sessions = c(1)
data_path = "~/Dropbox/MC-Projects/imaging-value-cert-att/striwp1"
raw.data <- get_participant_data(subjects, sessions, data_path, folstr="behav")
# Show it:
# raw.data %>% head(5)
# clean sub data (remove incorrect responses, and resps > 3 sds above the participant median)
sub.data <- lapply(subjects, clean.sub.data, data = raw.data)
sub.data <- do.call(rbind, sub.data)
# compute accuracy and inverse efficiency respectively from the two data frames (raw.data and sub.data),
acc.data = raw.data %>% group_by(sub, reward_type, cert) %>%
summarise(acc = mean(resp))
sum.inv.eff = sub.data %>% group_by(sub, reward_type, cert) %>%
summarise(RT = median(rt)) %>%
inner_join(acc.data, sum.inv.eff, by=c("sub", "reward_type", "cert")) %>%
transform(inv_eff = RT/acc)
fig.cols = wes_palette("IsleofDogs1")[4:1]
IE <- plot.behav(sum.inv.eff, dv="inv_eff", iv="cert", grp="reward_type", ylims =c(0.4, 2), cols = fig.cols) + xlab("") + ylab("IE") +
scale_y_continuous(breaks=pretty_breaks(n=5)) + theme_cowplot()
RT <- plot.behav(sum.inv.eff, dv="RT", iv="cert", grp="reward_type", ylims =c(0.4, 0.9), cols = fig.cols) + xlab("cue certainty") +
scale_y_continuous(breaks=pretty_breaks(n=5)) + theme_cowplot()
ACC <- plot.behav(sum.inv.eff, dv="acc", iv="cert", grp="reward_type", ylims =c(0, 1), cols = fig.cols) + xlab("") + ylab("ACC") +
scale_y_continuous(breaks=pretty_breaks(n=5)) + theme_cowplot()
# arrange plots
prow <- plot_grid(
RT + theme(legend.position = "none"),
ACC + theme(legend.position = "none"),
IE + theme(legend.position = "none"),
align = 'vh',
labels=c("A", "B", "C"),
hjust=-1,
nrow=1
)
# extract the legend from one of the plots
legend <- get_legend(
# create some space to the left of the legend
RT + theme(legend.box.margin = margin(0, 0, 0, 12))
)
# add the legend to the row we made earlier. Give it one-third of
# the width of one plot (via rel_widths).
plot_grid(prow, legend, rel_widths = c(3, .5))
# note: refer to previous analysis
sub.model <- function(data, csub){
data = data %>% filter(sub == csub)
mod <- with(data, aov( rt ~ cert*reward_type+Error(factor(t)) ))
mod
}
incls = lapply( unique(sub.data$sub), sub.model, data = sub.data  )
lapply(as.numeric(unique(sub.data$sub)), function(x) summary(incls[[x]]))
sessions = c(2, 3, 4)
TRs = c(700, 1510, 1920)
mri.beh.raw <- get_mri_data(subjects, sessions, data_path, TRs)
RT_min = .2
sd_reject = 2.5
mri.beh.clean <- mri.beh.raw %>% group_by(sub, sess, TR, reward_type, cert) %>%
filter(rt > RT_min) %>%
filter(resp == 1) %>%
filter(rt < median(rt) + sd_reject*sd(rt))
mri.acc = mri.beh.raw %>% group_by(sub, TR, reward_type, cert) %>%
summarise(acc = mean(resp))
mri.inv.eff = mri.beh.clean %>% group_by(sub, TR, reward_type, cert) %>%
summarise(RT = median(rt)) %>%
inner_join(mri.acc, sum.inv.eff, by=c("sub", "TR", "reward_type", "cert")) %>%
transform(inv_eff = RT/acc)
plot.mri(mri.inv.eff, dv="inv_eff", iv="cert", grp="reward_type", facet="TR", ylims =c(0.4, 1), cols = fig.cols) + ylab("IE") + xlab("cue certainty")
paradigm.fig.pth <- '../images/Fig_CNR_CN.png'
#paradigm.fig <- readPNG(paradigm.fig.pth, native=TRUE, info=TRUE)
include_graphics(paradigm.fig.pth)
# Load and tidy data
CNR = read.csv('~/Dropbox/MC-Projects/imaging-value-cert-att/striwp1/TDFASTT-data/CNR_aggregated.csv')
CNR$sub <- factor(CNR$sub)
CNR$TR <- factor(CNR$TR)
CNR$roi <- factor(CNR$roi)
CNR$contrast <- factor(CNR$contrast)
CNR$roi <- CNR$roi %>% recode('1' = 'CN',
'2' = 'FEF',
'3' = 'GPe',
'4' = 'GPi',
'5' = 'IPS',
'6' = 'LOC',
'7' = 'Put',
'8' = 'STN',
'9' = 'VS')
CNR$contrast <- CNR$contrast %>%  recode('1' = 'tgtLoc',
'2' = 'cueP',
'3' = 'cueP x tgtLoc',
'4' = 'AValue',
'5' = 'RelValue',
'6' = 'Value',
'7' = 'hand')
CNR <- CNR %>% mutate(roi=factor(roi, levels = c('FEF', 'IPS', 'LOC', 'VS', 'CN', 'Put', 'GPe', 'GPi', 'STN')))
with(CNR, boxplot(R~contrast*roi*TR))
# is it subject 1?
with(CNR[CNR$sub != "1", ], boxplot(R~contrast*roi*TR))
# subject 1 is > 3 sdevs from the mean on all measures, so excluding from the CNR analysis
CNR <- CNR %>% filter(sub != "1")
draw.sub.plts <- function(data, C){
blanks = data %>% filter(contrast==C) %>%
group_by(roi) %>%
summarise(min=min(R),
max=max(R))
data %>% filter(contrast == C) %>%
ggplot(aes(x=TR, y=R, group=sub)) +
geom_line(aes(color=sub), lwd=1.1) + facet_wrap(.~roi, scales="free_y") +
scale_colour_manual(values=c(wes_palette("Darjeeling2"))) +
scale_y_continuous(breaks=pretty_breaks(n=4)) +
scale_x_discrete("P", labels=c("1","2","3")) +
labs(y="RMS CNR") +
theme_cowplot() +
theme(strip.background=element_blank(), strip.placement="outside",
axis.title.x = element_text(face="italic"),
axis.title.y = element_text(face="italic"))
}
draw.sub.plts(CNR, C="hand")
ggsave("hand_RMS_CNR.pdf", dpi=300)
# this code shows the main effect of TR, and then shows the followup comparisions
library(car)
regs = c('VS', 'CN', 'Put', 'GPe', 'GPi', 'STN') # get subcortical ROIs
hand.dat <- CNR %>% filter(roi %in% regs & contrast == "hand")
omni <- Anova(lm(R ~ TR * roi, data=hand.dat, contrasts=list(topic=contr.sum, sys=contr.sum)), type=3)
FUa <- Anova(lm(R ~ TR * roi, data=hand.dat %>% filter(TR %in% c("700", "1510")), contrasts=list(topic=contr.sum, sys=contr.sum)), type=3)
FUb <- Anova(lm(R ~ TR * roi, data=hand.dat %>% filter(TR %in% c("700", "1920")), contrasts=list(topic=contr.sum, sys=contr.sum)), type=3)
FUc <- Anova(lm(R ~ TR * roi, data=hand.dat %>% filter(TR %in% c("1510", "1920")), contrasts=list(topic=contr.sum, sys=contr.sum)), type=3)
# follow up FUb
lapply(regs, function(x) with(hand.dat %>% filter(TR %in% c("700", "1920") & roi==x), t.test(R[TR=="700"], R[TR=="1920"])))
detach("package:car",unload=TRUE)
draw.sub.plts(CNR, C="tgtLoc")
ggsave("Tgt_RMS_CNR.pdf", dpi=300)
FIR = read.csv('~/Dropbox/MC-Projects/imaging-value-cert-att/striwp1/FIR-data/FIR_data_across_subs.csv')
FIR$sub <- as.factor(FIR$sub)
FIR$TR <- as.factor(FIR$TR)
FIR$reg <- as.factor(FIR$reg)
FIR$condition <- as.factor(FIR$condition)
levels(FIR$condition) <- c("l","r")
regs <- c("FEF", "IPS", "LOC", "CN", "GPe", "GPi", "Put", "VS")
# separately extracting STN, as insufficient voxels to have tertiarty split,
# therefore using all of them
muSTN <- FIR %>% filter(reg == "STN") %>%
group_by(TR, reg, condition, order) %>%
summarise(beta = mean(value, na.rm=T))
muFIR <- FIR %>% filter(reg %in% regs) %>%
filter(third == 3) %>%
group_by(TR, reg, condition, order) %>%
summarise(beta = mean(value))
muFIR <- rbind(muFIR, muSTN)
muFIR %>%  ggplot(aes(x=order, y=beta, group=condition)) +
geom_line(aes(color=condition), lwd=1.1) + facet_grid(vars(TR), vars(reg)) +
xlab("t") +
scale_x_continuous(breaks=seq(2,18,by=2),
labels = c("2","","","","10","","","","18")) +
scale_y_continuous(breaks=seq(-0.025, .1, by = 0.025),
labels=c("","0","","","",".1")) +
scale_colour_manual(values=c(wes_palette("Royal2")[c(1:2)])) +
ylab(expression(beta)) + theme_cowplot()
ggsave("FIR_response.pdf", dpi=300)
rm(list=ls())
library(ggplot2)
library(cowplot)
x <- seq(0,1,by=0.01)
y <- seq(0,1,by=0.01)
data <- expand.grid(X=x, Y=y)
data$Z <- (data$X + data$Y)/sum(data$X,data$Y)
ggplot(data, aes(X, Y, fill=Z)) +
geom_tile() + scale_fill_gradient(low="white", high="blue") +
theme_cowplot() + xlab("likelihood (certain)") + ylab("incentive (reward) value")
### written by K. Garner, April 2020
### edited by Z. Nott, August 2020
### for the project 'On the detectability of effects in executive function and implicit learning tasks'
### Garner, KG*, Nydam, A*, Nott, Z., & Dux, PE
rm(list=ls())
### run analysis of sample size x effect size variability on the SRT data
# ----------------------------------------------------------------------------------------------------
# load packages and source function files
# setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory to the location of this file
# uncomment the below and run if you need to install the packages
# install.packages("tidyverse")
# install.packages("wesanderson")
# install.packages("cowplot")
library(wesanderson) # palette for some sweet figure colours
library(cowplot)
library(lme4) # for mixed effects modelling
library(ggridges)
library(parallel)
library(tidyverse) # for data wrangling
source("efilids_functions.R") # custom functions written for this project
source("R_rainclouds.R") # functions for plotting
set.seed(42) # testing diff seeds on output
# ----------------------------------------------------------------------------------------------------
# load data and wrangle into tidy form (see https://r4ds.had.co.nz/tidy-data.html), plus relabel to make
# labels a little simpler
# ----------------------------------------------------------------------------------------------------
dat = read.csv("../data/total_of_313_subs_VSL_task_trial_level_data.csv", header=TRUE)
# ----------------------------------------------------------------------------------------------------
# Create dataframe for analysis
# ----------------------------------------------------------------------------------------------------
# data frame contains TRUE ordering
prev.dat <- dat %>% select(Subj.No, Trial.No, Response, Target.Order, Accuracy)
prev.dat$Response <- as.factor(prev.dat$Response)
prev.dat$Target.Order <- as.factor(prev.dat$Target.Order)
prev.dat <- prev.dat %>% mutate(Response = recode(Response,
"122" = "Novel",
"109" = "Repeat"),
Target.Order = recode(Target.Order,
"1" = "Novel",
"2" = "Repeat"))
# ----------------------------------------------------------------------------------------------------
# define levels for simulations
# ----------------------------------------------------------------------------------------------------
sub.Ns = round(exp(seq(log(13), log(313), length.out = 20)))
sub.Ns = 13
n.perms =1# for each sample size, we will repeat our experiment n.perms times
k = 1000 #for Monte Carlo simulations for prevalence stats (applies to both first level and second level perms)
Np = 1000
cores = 30
### written by K. Garner, April 2020
### edited by Z. Nott, August 2020
### for the project 'On the detectability of effects in executive function and implicit learning tasks'
### Garner, KG*, Nydam, A*, Nott, Z., & Dux, PE
rm(list=ls())
### run analysis of sample size x effect size variability on the SRT data
# ----------------------------------------------------------------------------------------------------
# load packages and source function files
# setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory to the location of this file
# uncomment the below and run if you need to install the packages
# install.packages("tidyverse")
# install.packages("wesanderson")
# install.packages("cowplot")
library(wesanderson) # palette for some sweet figure colours
library(cowplot)
library(lme4) # for mixed effects modelling
library(ggridges)
library(parallel)
library(tidyverse) # for data wrangling
source("efilids_functions.R") # custom functions written for this project
source("R_rainclouds.R") # functions for plotting
set.seed(42) # testing diff seeds on output
# ----------------------------------------------------------------------------------------------------
# load data and wrangle into tidy form (see https://r4ds.had.co.nz/tidy-data.html), plus relabel to make
# labels a little simpler
# ----------------------------------------------------------------------------------------------------
dat = read.csv("../data/total_of_313_subs_VSL_task_trial_level_data.csv", header=TRUE)
# ----------------------------------------------------------------------------------------------------
# Create dataframe for analysis
# ----------------------------------------------------------------------------------------------------
# data frame contains TRUE ordering
prev.dat <- dat %>% select(Subj.No, Trial.No, Response, Target.Order, Accuracy)
prev.dat$Response <- as.factor(prev.dat$Response)
prev.dat$Target.Order <- as.factor(prev.dat$Target.Order)
prev.dat <- prev.dat %>% mutate(Response = recode(Response,
"122" = "Novel",
"109" = "Repeat"),
Target.Order = recode(Target.Order,
"1" = "Novel",
"2" = "Repeat"))
# ----------------------------------------------------------------------------------------------------
# define levels for simulations
# ----------------------------------------------------------------------------------------------------
sub.Ns = round(exp(seq(log(13), log(313), length.out = 20)))
sub.Ns = 13
n.perms =1# for each sample size, we will repeat our experiment n.perms times
k = 1000 #for Monte Carlo simulations for prevalence stats (applies to both first level and second level perms)
Np = 1000
cores = 30
# ----------------------------------------------------------------------------------------------------
# run simulations for t-test model, getting p values from t.tests, and cohen's d values, and save results to a list
# ----------------------------------------------------------------------------------------------------
subs  <- unique(prev.dat$Subj.No)
start  <-  Sys.time()
lapply(sub.Ns, function(x) run.outer(in.data=prev.dat, subs=subs, N=x, k=n.perms, j=1, cores=cores, ffx.f=run.os.t.test.sim, rfx.f=run.prev.test, fstem="VSL_N-%d_parent-%d.RData"))
end <-  Sys.time()
end - start
# ------------
setwd("~/Dropbox/QBI/efilids/super-effects/Super-Effects/R")
### written by K. Garner, April 2020
### edited by Z. Nott, August 2020
### for the project 'On the detectability of effects in executive function and implicit learning tasks'
### Garner, KG*, Nydam, A*, Nott, Z., & Dux, PE
rm(list=ls())
### run analysis of sample size x effect size variability on the SRT data
# ----------------------------------------------------------------------------------------------------
# load packages and source function files
# setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory to the location of this file
# uncomment the below and run if you need to install the packages
# install.packages("tidyverse")
# install.packages("wesanderson")
# install.packages("cowplot")
library(wesanderson) # palette for some sweet figure colours
library(cowplot)
library(lme4) # for mixed effects modelling
library(ggridges)
library(parallel)
library(tidyverse) # for data wrangling
source("efilids_functions.R") # custom functions written for this project
source("R_rainclouds.R") # functions for plotting
set.seed(42) # testing diff seeds on output
# ----------------------------------------------------------------------------------------------------
# load data and wrangle into tidy form (see https://r4ds.had.co.nz/tidy-data.html), plus relabel to make
# labels a little simpler
# ----------------------------------------------------------------------------------------------------
dat = read.csv("../data/total_of_313_subs_VSL_task_trial_level_data.csv", header=TRUE)
# ----------------------------------------------------------------------------------------------------
# Create dataframe for analysis
# ----------------------------------------------------------------------------------------------------
# data frame contains TRUE ordering
prev.dat <- dat %>% select(Subj.No, Trial.No, Response, Target.Order, Accuracy)
prev.dat$Response <- as.factor(prev.dat$Response)
prev.dat$Target.Order <- as.factor(prev.dat$Target.Order)
prev.dat <- prev.dat %>% mutate(Response = recode(Response,
"122" = "Novel",
"109" = "Repeat"),
Target.Order = recode(Target.Order,
"1" = "Novel",
"2" = "Repeat"))
# ----------------------------------------------------------------------------------------------------
# define levels for simulations
# ----------------------------------------------------------------------------------------------------
sub.Ns = round(exp(seq(log(13), log(313), length.out = 20)))
sub.Ns = 13
n.perms =1# for each sample size, we will repeat our experiment n.perms times
k = 1000 #for Monte Carlo simulations for prevalence stats (applies to both first level and second level perms)
Np = 1000
cores = 30
# ----------------------------------------------------------------------------------------------------
# run simulations for t-test model, getting p values from t.tests, and cohen's d values, and save results to a list
# ----------------------------------------------------------------------------------------------------
subs  <- unique(prev.dat$Subj.No)
start  <-  Sys.time()
lapply(sub.Ns, function(x) run.outer(in.data=prev.dat, subs=subs, N=x, k=n.perms, j=1, cores=cores, ffx.f=run.os.t.test.sim, rfx.f=run.prev.test, fstem="VSL_N-%d_parent-%d.RData"))
end <-  Sys.time()
end - start
# ------------
5.59*1000
5590/60
sub.Ns = round(exp(seq(log(13), log(313), length.out = 20)))
sub.Ns
### written by K. Garner, April 2020
### edited by Z. Nott, August 2020
### for the project 'On the detectability of effects in executive function and implicit learning tasks'
### Garner, KG*, Nydam, A*, Nott, Z., & Dux, PE
rm(list=ls())
### run analysis of sample size x effect size variability on the SRT data
# ----------------------------------------------------------------------------------------------------
# load packages and source function files
# setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory to the location of this file
# uncomment the below and run if you need to install the packages
# install.packages("tidyverse")
# install.packages("wesanderson")
# install.packages("cowplot")
library(wesanderson) # palette for some sweet figure colours
library(cowplot)
library(lme4) # for mixed effects modelling
library(ggridges)
library(parallel)
library(tidyverse) # for data wrangling
source("efilids_functions.R") # custom functions written for this project
source("R_rainclouds.R") # functions for plotting
set.seed(42) # testing diff seeds on output
# ----------------------------------------------------------------------------------------------------
# load data and wrangle into tidy form (see https://r4ds.had.co.nz/tidy-data.html), plus relabel to make
# labels a little simpler
# ----------------------------------------------------------------------------------------------------
dat = read.csv("../data/total_of_313_subs_VSL_task_trial_level_data.csv", header=TRUE)
# ----------------------------------------------------------------------------------------------------
# Create dataframe for analysis
# ----------------------------------------------------------------------------------------------------
# data frame contains TRUE ordering
prev.dat <- dat %>% select(Subj.No, Trial.No, Response, Target.Order, Accuracy)
prev.dat$Response <- as.factor(prev.dat$Response)
prev.dat$Target.Order <- as.factor(prev.dat$Target.Order)
prev.dat <- prev.dat %>% mutate(Response = recode(Response,
"122" = "Novel",
"109" = "Repeat"),
Target.Order = recode(Target.Order,
"1" = "Novel",
"2" = "Repeat"))
# ----------------------------------------------------------------------------------------------------
# define levels for simulations
# ----------------------------------------------------------------------------------------------------
sub.Ns = round(exp(seq(log(13), log(313), length.out = 20)))
sub.Ns = 42
n.perms =1# for each sample size, we will repeat our experiment n.perms times
k = 1000 #for Monte Carlo simulations for prevalence stats (applies to both first level and second level perms)
Np = 1000
cores = 30
# ----------------------------------------------------------------------------------------------------
# run simulations for t-test model, getting p values from t.tests, and cohen's d values, and save results to a list
# ----------------------------------------------------------------------------------------------------
subs  <- unique(prev.dat$Subj.No)
start  <-  Sys.time()
lapply(sub.Ns, function(x) run.outer(in.data=prev.dat, subs=subs, N=x, k=n.perms, j=1, cores=cores, ffx.f=run.os.t.test.sim, rfx.f=run.prev.test, fstem="VSL_N-%d_parent-%d.RData"))
end <-  Sys.time()
end - start
13.76*1000
13760/60
229.33/60
### written by K. Garner, April 2020
### edited by Z. Nott, August 2020
### for the project 'On the detectability of effects in executive function and implicit learning tasks'
### Garner, KG*, Nydam, A*, Nott, Z., & Dux, PE
rm(list=ls())
### run analysis of sample size x effect size variability on the SRT data
# ----------------------------------------------------------------------------------------------------
# load packages and source function files
# setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory to the location of this file
# uncomment the below and run if you need to install the packages
# install.packages("tidyverse")
# install.packages("wesanderson")
# install.packages("cowplot")
library(wesanderson) # palette for some sweet figure colours
library(cowplot)
library(lme4) # for mixed effects modelling
library(ggridges)
library(parallel)
library(tidyverse) # for data wrangling
source("efilids_functions.R") # custom functions written for this project
source("R_rainclouds.R") # functions for plotting
set.seed(42) # testing diff seeds on output
# ----------------------------------------------------------------------------------------------------
# load data and wrangle into tidy form (see https://r4ds.had.co.nz/tidy-data.html), plus relabel to make
# labels a little simpler
# ----------------------------------------------------------------------------------------------------
dat = read.csv("../data/total_of_313_subs_VSL_task_trial_level_data.csv", header=TRUE)
# ----------------------------------------------------------------------------------------------------
# Create dataframe for analysis
# ----------------------------------------------------------------------------------------------------
# data frame contains TRUE ordering
prev.dat <- dat %>% select(Subj.No, Trial.No, Response, Target.Order, Accuracy)
prev.dat$Response <- as.factor(prev.dat$Response)
prev.dat$Target.Order <- as.factor(prev.dat$Target.Order)
prev.dat <- prev.dat %>% mutate(Response = recode(Response,
"122" = "Novel",
"109" = "Repeat"),
Target.Order = recode(Target.Order,
"1" = "Novel",
"2" = "Repeat"))
# ----------------------------------------------------------------------------------------------------
# define levels for simulations
# ----------------------------------------------------------------------------------------------------
sub.Ns = round(exp(seq(log(13), log(313), length.out = 20)))
sub.Ns = 313
n.perms =1# for each sample size, we will repeat our experiment n.perms times
k = 1000 #for Monte Carlo simulations for prevalence stats (applies to both first level and second level perms)
Np = 1000
cores = 30
# ----------------------------------------------------------------------------------------------------
# run simulations for t-test model, getting p values from t.tests, and cohen's d values, and save results to a list
# ----------------------------------------------------------------------------------------------------
subs  <- unique(prev.dat$Subj.No)
start  <-  Sys.time()
lapply(sub.Ns, function(x) run.outer(in.data=prev.dat, subs=subs, N=x, k=n.perms, j=1, cores=cores, ffx.f=run.os.t.test.sim, rfx.f=run.prev.test, fstem="VSL_N-%d_parent-%d.RData"))
end <-  Sys.time()
end - start
1.5*1000
1500/60
