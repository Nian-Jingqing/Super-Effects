---
title: "super-fx"
author: "Knott, Z., Nydam, A., Bowman, H., Dux, PE., & Garner, KG."
date: '`r format(Sys.time())`'
output:
  bookdown::pdf_document2:
    includes:
      before_body: ../template/doc_prefix.tex
      in_header: ../template/preamble.tex
    keep_tex: yes
    latex_engine: xelatex
    number_sections: no
    toc: no
  bookdown::html_document2:
    number_sections: no
    theme: readable
    toc: yes
  bookdown::tufte_html2:
    number_sections: no
    toc: yes
  bookdown::word_document2: null
fontsize: 12pt
linestretch: 1.5
link-citations: yes
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/chicago-annotated-bibliography.csl
bibliography: ../template/ref.bib
always_allow_html: yes
links-as-notes: true
---

```{r knitr_options, echo=FALSE}
library(knitr)
# rstudio will set the folder where .Rmd file seats as work directory
# set it back to the folder where .Rproj seats
opts_knit$set(root.dir = normalizePath("../")) 
opts_chunk$set(fig.align = 'center', cache = FALSE, warning = FALSE,
  message = TRUE, echo = FALSE)
options(digits = 3, width = 88, knitr.graphics.auto_pdf = TRUE,
        knitr.kable.NA = '')
# download template files if not available
tpl_1 = 'https://raw.githubusercontent.com/daijiang/workflow_demo/master/template/preamble.tex'
tpl_2 = 'https://raw.githubusercontent.com/daijiang/workflow_demo/master/template/doc_prefix.tex'
bib_1 = 'doc/refs.bib'
# change directory accordingly
if(!file.exists(tpl_1f <- '../template/preamble.tex')) download.file(tpl_1, tpl_1f)
if(!file.exists(tpl_2f <- '../template/doc_prefix.tex')) download.file(tpl_2, tpl_2f)
if(knitr::is_latex_output() | knitr::is_html_output()){
  library(kableExtra)
} else {
  options(kableExtra.auto_format = FALSE) # for docx
}
```

```{r loadpackagesandfunctions, echo=FALSE, message=F, warning=F}
library(tidyverse)
library(wesanderson)
library(ggridges)
library(cowplot)
source('../R/efilids_functions.R')
source('../R/R_rainclouds.R')
```

**Running headline**: Environment and species richness

**Abstract**: Your awesome abstract here.

\clearpage

# Introduction

Here is your introduction. It should describe clearly the rationale for the study being done and the previous work related with the study. It should also tell readers about your specific hypothese/questions being addressed. Citations will be like this [@adair_single-pool_2010], or [e.g., @clark_loss_2008], or [@eriksson_seed_1993; @williamson_dissolved_1999]

Here is the second paragraph of the introduction. 


# Methods

### Participants


### Apparatus


### Task Procedures


### Simulation protocol

Effect sizes: _FFX_: where required, Cohen's $d$ was attained by converting partial eta square using the formula defined in [https://www.journalofcognition.org/articles/10.5334/joc.10/].
_RFX_: as defined in [add ref above], an approximation of Cohen's $d$ was attained by computing the ratio of the proportion of variance explained by the regressor of interest, relative to the remaining regressors in the model (including the error variance).

Extra simulations were each run with an extra error term for the T1 or T2 stimulus (AB and SD), for experimentor ID, or for task-order, but the results suggested that the addition of an extra random effect resulted in a model structure that was too complex for the data.


### Model definitions

RFX: e.g. AB $$y_{ij} \sim lag + e_{i} + e_{ij}$$
Tested for significance by performing the likelihood ratio test between the model containing the effect of interest and the null model (see each task for definitions).


[Will prob move the below to the relevant section in the results]
#### Attentional Blink 

_FFX_: A repeated-measures ANOVA with one factor (lag: 2, 3, 5 & 7) was performed. Cohen's $d$ is reported for the main effect of lag. _RFX_: For the RFX analysis we included an extra intercept term for each subject. Again, Cohen's $d$ is reported for the main effect of lag. To test for the statistical significance of the main effect of lag, the RFX model containing the lag term was compared to the model containing the subject and error intercepts. 

#### Dual-task

_FFX_: Data were modelled using a 2 (modality: visual vs auditory) x 2 (task: single vs dual) repeated-measures ANOVA. Cohen's $d$ is reported for the main effect of task. _RFX_: The RFX model of interest contained an additional intercept term for each subject. To test for the statistical significance of the main effect of task, the model of interest was compared to a null model that contained only the regressor for modality, and the subject and error intercepts. 

#### Contextual Cueing

_FFX_: A block (1:12) x condition (repeat vs novel) repeated-measures ANOVA was applied to the data. Cohen's $d$ is reported for the block x condition interaction. _RFX_: An additional intercept term for each subject was added to the main model of interest. To test for statistical significance of the block x condition interaction, the model of interest was compared to a null model that contained only regressors for the main effect of block, the main effect of task, and the subject intercept terms. 

#### Serial Response Task 

_FFX_: For the SRT data, mean RTs from repeat and novel sequences were compared using a within-subjects t-test. _RFX_: A linear mixed effects model with a regressor for condition (repeat vs novel) and a subject intercept term was compared to a null model that contained only the subject intercept term.  

## Results

### Attentional Blink

```{r, ABsimresults, fig.width=7, fig.asp=1, fig.cap="AB simulation results. A) showing Cohen's {d} attained for each sample size for the FFX modelling for the main effect of lag, B) showing Cohen's $d$ attained from the RFX modelling of lag + subject intercept, C) showing the log p-values attained across simulations at each sample size N for the FFX model, the vertical dashed line shows log(p=.05). Note: all p-values to the left of this line would result in a rejection of the null hypothesis.  D) same as C, except for the RFX model."}

load('../data/AB_sim_data.RData')
 
# first tidy up the FFX and RFX data for plotting
sims.dat <- sims.dat %>% filter(fx != "stim") 
ffx.d.p <- plt.fx.sz(sims.dat[sims.dat$model == "FFX", ], c(0,2))
rfx.sub.d.p <- plt.fx.sz(sims.dat[sims.dat$model == "RFX", ], c(1,3))

# now for p-values
xlims=c(-600,0)
p.dat <- sims.dat %>% filter(measure == "p") %>% mutate(value=log(value))
ffx.p.p <- plt.ps(p.dat[p.dat$model=="FFX",], xlims, .01) + geom_vline(aes(xintercept=log(.05)), linetype="dashed") + xlab("log(p)")
rfxsub.p.p <- plt.ps(p.dat[p.dat$model=="RFX",], xlims, .01) + geom_vline(aes(xintercept=log(.05)), linetype="dashed") + theme_cowplot() + xlab("log(p)")

# use cowplot to make a grid
p = plot_grid(ffx.d.p, rfx.sub.d.p, ffx.p.p, rfxsub.p.p, labels=c('A', 'B', 'C', 'D'), label_size = 12, align="v")
p

```

Notes: large Cohen's $d$, it looks like RFX modelling suggests a larger range of effect sizes for smaller sample sizes, but that this issue goes away as the precision capacity of the estimate increases. For FFX, sample sizes > 18 ensure the alternate will not be rejected, whereas for RFX, all exp sizes = reject null.  

Idea: ratio of range of d-values for each model/N?

```{r, delAB, echo=FALSE, message=F, warning=F}
# clean up AB data
rm(list=ls(pattern=".d.p"))
rm(list=ls(pattern=".p.p"))
rm(list=c("p", "p.dat", "rfx", "sims.dat"))
```

### Dual-task

```{r, SDsimresults, warning=F, echo=F, fig.width=7, fig.asp=1, fig.cap="Dual-task simulation results. A) showing Cohen's {d} attained for each sample size for the FFX modelling for the main effect of task (single vs dual), B) showing Cohen's $d$ attained from the RFX modelling with an additional subject intercept, C) showing the log p-values attained across simulations at each sample size N for the FFX model, the vertical dashed line shows log(p=.05). D) same as C, except for the RFX model."}

load('../data/SD_sim_data.RData')
ylims = c(0,3)
ffx.d.p <- plt.fx.sz(sims.dat[sims.dat$model == "FFX", ], c(0,2))
rfx.d.p <- plt.fx.sz(sims.dat[sims.dat$model == "RFX", ], c(1,3))

# as p-values are all below .05 across sims, I am going to do a single facet_wrapped density plot, showing the 
# p-values across all simulations
xlims=c(-800,0)
p.dat <- sims.dat %>% filter(measure == "p") %>% mutate(value=log(value))
p.dat <- p.dat[!is.infinite(p.dat$value),]
ffx.p.p <- plt.ps(p.dat[p.dat$model=="FFX",], xlims, .01) + geom_vline(aes(xintercept=log(.05)), linetype="dashed") + xlab("log(p)")
rfx.p.p <- plt.ps(p.dat[p.dat$model=="RFX",], xlims, .01) + geom_vline(aes(xintercept=log(.05)), linetype="dashed") + xlab("log(p)")

p = plot_grid(ffx.d.p, rfx.d.p, ffx.p.p, rfx.p.p, labels=c('A', 'B', 'C', 'D'), label_size = 12, align="v")
p

```

All is a similar story to the AB

```{r, delSD, echo=FALSE, message=F, warning=F}
# clean up AB data
rm(list=ls(pattern=".d.p"))
rm(list=ls(pattern=".p.p"))
rm(list=c("p", "p.dat", "rfx", "sims.dat"))
```

### Contextual Cueing

```{r, CCsimresults, warning=F, echo=F, fig.width=7, fig.asp=1, fig.cap="Contextual-cueing simulation results. A) showing Cohen's {d} attained for each sample size for the FFX modelling for the interaction of block x condition (repeat vs novel), B) showing Cohen's $d$ attained from the RFX modelling with an additional subject intercept, C) showing the log p-values attained across simulations at each sample size N for the FFX model, the vertical dashed line shows log(p=.05). D) same as C, except for the RFX model."}

load('../data/CC_sim_data.RData')
ylims = c(0,0.5)
ffx.d.p <- plt.fx.sz(sims.dat[sims.dat$model == "FFX", ], ylims)
rfx.d.p <- plt.fx.sz(sims.dat[sims.dat$model == "RFX", ], ylims)

xlims=c(-50,1)
p.dat <- sims.dat %>% filter(measure == "p") %>% mutate(value=log(value))
p.dat <- p.dat[!is.infinite(p.dat$value),]
ffx.p.p <- plt.ps(p.dat[p.dat$model=="FFX",], xlims, .01) + geom_vline(aes(xintercept=log(.05)), linetype="dashed") 
rfx.p.p <- plt.ps(p.dat[p.dat$model=="RFX",], xlims, .01) + geom_vline(aes(xintercept=log(.05)), linetype="dashed") 

p = plot_grid(ffx.d.p, rfx.d.p, ffx.p.p, rfx.p.p, labels=c('A', 'B', 'C', 'D'), label_size = 12, align="v")
p

```

Putative reason for differences in effect size observations between FFX and RFX: FFX models deviations from the grand mean - therefore a subject that shows a large deviation from the grand mean can inflate the variance soaked up by the condition regressor. As the RFX model includes a subject intercept, the regressor of interest can only soak up the variance of interest.

Q: are large effect size observations driven by individuals who are far from the grand mean?

- note from Chris: plot effect size vs p
- also, can you get sig with consistent d=.05 across subs?

One clue towards these thoughts would be if the subject intercept estimates showed, on some simulations, larger values than on other simulations - i.e. the distribution should be skewed or bimodal.

```{r, CCRFX, warning=F, echo=F, fig.width=5, fig.asp=1, fig.cap="Estimates of the residual and subject intercept terms from the Contextual-cueing RFX simulations. A) showing standard deviations of the estimated Residual error distribution, B) the standard deviations for the subject intercept distribution."}


# tidy rfx and convert variances to standard deviation
rfx$model = "blk:cond"
rfx <- rfx %>% mutate(esub = sqrt(esub),
                      eRes = sqrt(eRes))
rfx.p <- plt.rfx(rfx, c(min(c(rfx$esub, rfx$eRes)), max(c(rfx$esub, rfx$eRes)))) + xlab("SD") + theme_cowplot()
rfx.p

```

```{r, delCC, echo=FALSE, message=F, warning=F}
# clean up AB data
rm(list=ls(pattern=".d.p"))
rm(list=ls(pattern=".p.p"))
rm(list=c("p", "p.dat", "rfx", "sims.dat"))
```

### Serial Response Task

```{r, SRTsimresults, warning=F, echo=F, fig.width=7, fig.asp=1, fig.cap="Serial Response Task simulation results. A) showing Cohen's {d} attained for each sample size for the FFX modelling, using a within-subjects t-test to compare condition (repeat vs novel), B) showing Cohen's $d$ attained from the RFX modelling with an additional subject intercept, C) showing the log p-values attained across simulations at each sample size N for the FFX model, the vertical dashed line shows log(p=.05). D) same as C, except for the RFX model."}

load('../data/SRT_sim_data.RData')
ylims = c(0,0.5)
ffx.d.p <- plt.fx.sz(sims.dat[sims.dat$model == "FFX", ], ylims)
rfx.d.p <- plt.fx.sz(sims.dat[sims.dat$model == "RFX", ], ylims)

xlims=c(-800,0)
p.dat <- sims.dat %>% filter(measure == "p") %>% mutate(value=log(value))
p.dat <- p.dat[!is.infinite(p.dat$value),]
ffx.p.p <- plt.ps(p.dat[p.dat$model=="FFX",], c(-10,1), .01) 
rfx.p.p <- plt.ps(p.dat[p.dat$model=="RFX",], xlims, .01) 

p = plot_grid(ffx.d.p, rfx.d.p, ffx.p.p, rfx.p.p, labels=c('A', 'B', 'C', 'D'), label_size = 12, align="v")
p

```

Note: FFX leads you awry far more often than RFX
Modelling subject means is important for implicit learning tasks.

```{r, delSRT, echo=FALSE, message=F, warning=F}
# clean up AB data
rm(list=ls(pattern=".d.p"))
rm(list=ls(pattern=".p.p"))
rm(list=c("p", "p.dat", "rfx", "sims.dat"))
```


### Visual Statistical Learning


#### Tables

Insert tables by `kable` in knitr package in R. Then cross-reference it back with: see Table \@ref(tab:tableName).


```{r tableName,results='asis',echo=FALSE, message=F, warning=F}
source("R/rcode.R")
knitr::kable(sprich, booktabs = T, caption = "Caption here.")
```

Put results inline, e.g. the mean species richness is `r meansprich`.

#### Insert tables by `xtable` package in R


Show as Table. \ref{t:anova}:

```{r echo=F,results='asis',warning=F,message=F}
library(xtable)
envi.summ = xtable(summary(envi.aov),label = "t:anova", caption = "Caption here")
print(envi.summ,
		caption.placement = "top",
	  floating=T,
	  hline.after=NULL,
	  comment = FALSE,
	  add.to.row=list(pos=list(-1,0, nrow(envi.summ)),
	  command=c(
		   '\\toprule\n',
		  '\\midrule\n',
		   '\\bottomrule\n')))
```

#### Insert tables by hand


Show as Table. \@ref(tab:byhand):

Table: (#tab:byhand) Caption here.

Col A             Col B       Col C                   Col D
------------      -------     ------------------      ------------------
row 1             190         $112 \pm 2$             $233 \pm 3$
$\eta$            0.13        0.12                    0.12
$\eta^2$          0.14        0.13                    0.50
$\eta^3$          0.15        0.31                    0.52


#### Figures

Insert figure by code chunk. And cross-ref it back as Figure \@ref(fig:figName).

```{r figName, fig.width=7, fig.asp=1, fig.cap="Your caption here."}
ggplot(data = envi.sprich, aes(x = value, y = sprich)) +
  geom_point() + geom_smooth(method = "lm") +
  facet_wrap(~envi, scales = "free_x") + theme_bw()
```


Or if you already have the figure: 
And cite it as Figure \@ref(fig:fig2).

```{r fig2, out.width='70%', fig.cap="Caption here."}
knitr::include_graphics(path = paste0(normalizePath(getwd()), "/Figs/plot.pdf"))
```


More details can be found at [here](https://bookdown.org/yihui/bookdown/).

# References